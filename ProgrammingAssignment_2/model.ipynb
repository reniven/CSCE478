{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JUPYTER NOTEBOOK TIPS\n",
    "\n",
    "Each rectangular box is called a cell. \n",
    "* ctrl+ENTER evaluates the current cell; if it contains Python code, it runs the code, if it contains Markdown, it returns rendered text.\n",
    "* alt+ENTER evaluates the current cell and adds a new cell below it.\n",
    "* If you click to the left of a cell, you'll notice the frame changes color to blue. You can erase a cell by hitting 'dd' (that's two \"d\"s in a row) when the frame is blue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning Model Skeleton\n",
    "\n",
    "We'll use this skeleton for implementing different supervised learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "        \n",
    "    def fit(self):\n",
    "        \n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def predict(self, test_points):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(data_f, feature_names_f):\n",
    "    '''\n",
    "    data_f: where to read the dataset from\n",
    "    feature_names_f: where to read the feature names from\n",
    "    Returns:\n",
    "        features: ndarray\n",
    "            nxd array containing `float` feature values\n",
    "        labels: ndarray\n",
    "            1D array containing `float` label\n",
    "    '''\n",
    "    # You might find np.genfromtxt useful for reading in the file. Be careful with the file delimiter, \n",
    "    # e.g. for comma-separated files use delimiter=',' argument.\n",
    "    \n",
    "    data = np.genfromtxt(data_f)\n",
    "    features = data[:,:-1]\n",
    "    target = data[:,-1]\n",
    "    feature_names = np.genfromtxt(feature_names_f, dtype='unicode')\n",
    "    \n",
    "    return features, feature_names, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In cases where data is not abundantly available, we resort to getting an error estimate from average of error on different splits of dataset. In this case, every fold of data is used for testing and for training in turns, i.e. assuming we split our data into 3 folds, we'd\n",
    "* train our model on fold-1+fold-2 and test on fold-3\n",
    "* train our model on fold-1+fold-3 and test on fold-2\n",
    "* train our model on fold-2+fold-3 and test on fold-1.\n",
    "\n",
    "We'd use the average of the error we obtained in three runs as our error estimate. \n",
    "\n",
    "Implement function \"kfold\" below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Programming Assignment 2\n",
    "import numpy as np\n",
    "def kfold(size, k):\n",
    "\n",
    "    '''\n",
    "    Args:\n",
    "        size: int\n",
    "            number of examples in the dataset that you want to split into k\n",
    "        k: int \n",
    "            Number of desired splits in data.(Assume test set is already separated.)\n",
    "        Returns:\n",
    "        fold_dict: dict\n",
    "            A dictionary with integer keys corresponding to folds. Values are (training_indices, val_indices).\n",
    "        \n",
    "        val_indices: ndarray\n",
    "            1/k of training indices randomly chosen and separates them as validation partition.\n",
    "        train_indices: ndarray\n",
    "            Remaining 1-(1/k) of the indices.\n",
    "            \n",
    "            e.g. fold_dict = {0: (train_0_indices, val_0_indices), \n",
    "            1: (train_0_indices, val_0_indices), 2: (train_0_indices, val_0_indices)} for k = 3\n",
    "    '''\n",
    "    n = int(size/k)\n",
    "    fold_dict = {}\n",
    "    \n",
    "    test = 0\n",
    "    for i in range (0,size):\n",
    "        train_indicies = []\n",
    "        Array_range = (n+test)-1\n",
    "        #print('Array_range',Array_range)\n",
    "        val_indice = np.arange(test,Array_range)\n",
    "        test = Array_range\n",
    "        #print('test',test)\n",
    "        #print(val_indice)\n",
    "        for y in range (0,size):\n",
    "            if y not in val_indice:\n",
    "                train_indicies.append(y)\n",
    "        #print(train_indicies)\n",
    "        fold_dict[i] = (train_indicies,val_indice)\n",
    "    return fold_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement \"mse\" and regularization functions. They will be used in the fit method of linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: Programming Assignment 2\n",
    "import numpy as np\n",
    "def mse(y_pred, y_true):\n",
    "    '''\n",
    "    Args:\n",
    "        y_hat: ndarray \n",
    "            1D array containing data with `float` type. Values predicted by our method\n",
    "        y_true: ndarray\n",
    "            1D array containing data with `float` type. True y values\n",
    "    Returns:\n",
    "        cost: ndarray\n",
    "            1D array containing mean squared error between y_pred and y_true.\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    #test = 0\n",
    "    cost = 0\n",
    "    #for i in range (0,len(y_pred)):\n",
    "    cost = np.mean(((y_true - y_pred)**2)/len(y_pred))\n",
    "        #cost.append(test)\n",
    "    #raise NotImplementedError\n",
    "\n",
    "    return cost\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: Programming Assignment 2\n",
    "def regularization(weights, method):\n",
    "    '''\n",
    "    Args:\n",
    "        weights: ndarray\n",
    "            1D array with `float` entries\n",
    "        method: str\n",
    "    Returns:\n",
    "        value: float\n",
    "            A single value. Regularization term that will be used in cost function in fit.\n",
    "    '''\n",
    "    value = 0\n",
    "    \n",
    "    if method == \"l1\":\n",
    "        for i in range (0,len(weights)):\n",
    "            value +=  abs(weights[i])\n",
    "    elif method == \"l2\":\n",
    "        for y in range (0,len(weights)):\n",
    "            value += (abs(weights[y])**2)\n",
    "    #raise NotImplementedError\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
